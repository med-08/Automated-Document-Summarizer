{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6adc2242",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-11T17:43:14.366970Z",
     "iopub.status.busy": "2025-04-11T17:43:14.366596Z",
     "iopub.status.idle": "2025-04-11T17:43:25.096653Z",
     "shell.execute_reply": "2025-04-11T17:43:25.095488Z"
    },
    "papermill": {
     "duration": 10.735521,
     "end_time": "2025-04-11T17:43:25.098717",
     "exception": false,
     "start_time": "2025-04-11T17:43:14.363196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\r\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\r\n",
      "Collecting docopt<0.7,>=0.6.1 (from sumy)\r\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting breadability>=0.1.20 (from sumy)\r\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from sumy) (2.32.3)\r\n",
      "Collecting pycountry>=18.2.23 (from sumy)\r\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from sumy) (3.9.1)\r\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\r\n",
      "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.3.1)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (8.1.8)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (4.67.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2025.1.31)\r\n",
      "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: breadability, docopt\r\n",
      "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21691 sha256=0b4a5e6e6510ee3092fafaec40e6908c081988a60829bdb2e87e63fb67b94f40\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/4d/57/58/7e3d7fedf51fe248b7fcee3df6945ae28638e22cddf01eb92b\r\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=61aaf4ae630168a807e6080501d480686356dec0de403bc0a01696925162556c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\r\n",
      "Successfully built breadability docopt\r\n",
      "Installing collected packages: docopt, pycountry, breadability, sumy\r\n",
      "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-24.6.1 sumy-0.11.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d925897e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T17:43:25.106286Z",
     "iopub.status.busy": "2025-04-11T17:43:25.105932Z",
     "iopub.status.idle": "2025-04-11T17:49:11.282529Z",
     "shell.execute_reply": "2025-04-11T17:49:11.281452Z"
    },
    "papermill": {
     "duration": 346.184902,
     "end_time": "2025-04-11T17:49:11.286836",
     "exception": false,
     "start_time": "2025-04-11T17:43:25.101934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Constrained Magnetic Resonance Spectroscopic I...</td>\n",
       "      <td>A regularization formulation is proposed to ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lightweight Pyramid Networks for Image Deraining.</td>\n",
       "      <td>In particular, we find that by introducing the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thorax-Net: An Attention Regularized Deep Neur...</td>\n",
       "      <td>The attention branch exploits the correlation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Correction to: Classification of Carotid Arter...</td>\n",
       "      <td>The original article unfortunately contained a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial Intelligence in Drug Treatment.</td>\n",
       "      <td>The most common applications of artificial int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Constrained Magnetic Resonance Spectroscopic I...   \n",
       "1  Lightweight Pyramid Networks for Image Deraining.   \n",
       "2  Thorax-Net: An Attention Regularized Deep Neur...   \n",
       "3  Correction to: Classification of Carotid Arter...   \n",
       "4         Artificial Intelligence in Drug Treatment.   \n",
       "\n",
       "                                             summary  \n",
       "0  A regularization formulation is proposed to ef...  \n",
       "1  In particular, we find that by introducing the...  \n",
       "2  The attention branch exploits the correlation ...  \n",
       "3  The original article unfortunately contained a...  \n",
       "4  The most common applications of artificial int...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('/kaggle/input/pubmed-abstracts/pubmed_abstracts.csv')\n",
    "\n",
    "# Parse deep learning column\n",
    "deep_df = df[['deep_learning']].copy()\n",
    "deep_df.dropna(inplace=True)\n",
    "\n",
    "# Convert the stringified tuple to actual list and title\n",
    "deep_df['parsed'] = deep_df['deep_learning'].apply(lambda x: ast.literal_eval(x))\n",
    "deep_df[['sentences', 'title']] = pd.DataFrame(deep_df['parsed'].tolist(), index=deep_df.index)\n",
    "\n",
    "# Combine sentences into full abstract text\n",
    "deep_df['full_abstract'] = deep_df['sentences'].apply(lambda sents: \" \".join(sents))\n",
    "\n",
    "# Setup TextRank summarizer\n",
    "def summarize_text(text, sentence_count=2):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = TextRankSummarizer()\n",
    "    summary = summarizer(parser.document, sentence_count)\n",
    "    return \" \".join([str(sentence) for sentence in summary])\n",
    "\n",
    "# Generate summaries for top 100 articles (adjust as needed)\n",
    "deep_df['summary'] = deep_df['full_abstract'].apply(lambda x: summarize_text(x, sentence_count=2))\n",
    "\n",
    "# Preview results\n",
    "deep_df[['title', 'summary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "788d747b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T17:49:11.293804Z",
     "iopub.status.busy": "2025-04-11T17:49:11.293467Z",
     "iopub.status.idle": "2025-04-11T17:49:11.534666Z",
     "shell.execute_reply": "2025-04-11T17:49:11.533500Z"
    },
    "papermill": {
     "duration": 0.246948,
     "end_time": "2025-04-11T17:49:11.536531",
     "exception": false,
     "start_time": "2025-04-11T17:49:11.289583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_df[['title', 'summary']].to_csv(\"summarized_articles.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 637555,
     "sourceId": 1132630,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 363.05898,
   "end_time": "2025-04-11T17:49:12.361919",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-11T17:43:09.302939",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
